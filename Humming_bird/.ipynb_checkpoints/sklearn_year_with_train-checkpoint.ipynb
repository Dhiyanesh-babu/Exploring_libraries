{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hummingbird.ml import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request as urllib\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip'\n",
    "\n",
    "filehandle, _ = urllib.urlretrieve(url)\n",
    "zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
    "filename = zip_file_object.namelist()[0]\n",
    "bytes_data = zip_file_object.open(filename).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "year = pd.read_csv(BytesIO(bytes_data), header = None)\n",
    "\n",
    "#train_size = 463715  # Note: this will extend the training time if we do the full dataset\n",
    "train_size = 200000\n",
    "X = year.iloc[:, 1:]\n",
    "y = year.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, train_size=train_size, test_size=51630)\n",
    "\n",
    "# Store the test data as numpy by pulling the values out of the pandas dataframe\n",
    "data = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>45.09540</td>\n",
       "      <td>-57.29138</td>\n",
       "      <td>20.05392</td>\n",
       "      <td>0.10414</td>\n",
       "      <td>12.00346</td>\n",
       "      <td>-14.31259</td>\n",
       "      <td>2.54547</td>\n",
       "      <td>-3.33986</td>\n",
       "      <td>-3.60175</td>\n",
       "      <td>-8.99414</td>\n",
       "      <td>...</td>\n",
       "      <td>7.15503</td>\n",
       "      <td>-81.48297</td>\n",
       "      <td>34.91722</td>\n",
       "      <td>15.11917</td>\n",
       "      <td>-6.09056</td>\n",
       "      <td>-78.52893</td>\n",
       "      <td>-46.87559</td>\n",
       "      <td>2.89571</td>\n",
       "      <td>64.25949</td>\n",
       "      <td>0.78578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200001</th>\n",
       "      <td>45.11673</td>\n",
       "      <td>-18.39958</td>\n",
       "      <td>-1.61552</td>\n",
       "      <td>-3.67929</td>\n",
       "      <td>-13.24027</td>\n",
       "      <td>-6.84375</td>\n",
       "      <td>-10.33838</td>\n",
       "      <td>-11.12891</td>\n",
       "      <td>16.56924</td>\n",
       "      <td>6.70243</td>\n",
       "      <td>...</td>\n",
       "      <td>8.26246</td>\n",
       "      <td>-138.26547</td>\n",
       "      <td>23.59451</td>\n",
       "      <td>60.99156</td>\n",
       "      <td>4.18891</td>\n",
       "      <td>105.75496</td>\n",
       "      <td>-126.39851</td>\n",
       "      <td>-3.80727</td>\n",
       "      <td>55.00532</td>\n",
       "      <td>-3.42354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>46.85191</td>\n",
       "      <td>9.44824</td>\n",
       "      <td>0.31518</td>\n",
       "      <td>-16.85413</td>\n",
       "      <td>15.42389</td>\n",
       "      <td>-15.82587</td>\n",
       "      <td>-21.21385</td>\n",
       "      <td>-10.16067</td>\n",
       "      <td>14.45113</td>\n",
       "      <td>2.22865</td>\n",
       "      <td>...</td>\n",
       "      <td>13.24783</td>\n",
       "      <td>-91.25475</td>\n",
       "      <td>41.12300</td>\n",
       "      <td>55.22389</td>\n",
       "      <td>8.33048</td>\n",
       "      <td>7.57355</td>\n",
       "      <td>17.34516</td>\n",
       "      <td>0.21543</td>\n",
       "      <td>-58.34520</td>\n",
       "      <td>3.92760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200003</th>\n",
       "      <td>45.79644</td>\n",
       "      <td>-36.86230</td>\n",
       "      <td>21.99320</td>\n",
       "      <td>-10.42360</td>\n",
       "      <td>-2.89410</td>\n",
       "      <td>-8.84010</td>\n",
       "      <td>-23.73864</td>\n",
       "      <td>-9.82956</td>\n",
       "      <td>13.08399</td>\n",
       "      <td>0.57577</td>\n",
       "      <td>...</td>\n",
       "      <td>8.13403</td>\n",
       "      <td>-194.21155</td>\n",
       "      <td>55.55883</td>\n",
       "      <td>21.65387</td>\n",
       "      <td>6.41164</td>\n",
       "      <td>-47.18867</td>\n",
       "      <td>-212.14270</td>\n",
       "      <td>-4.67550</td>\n",
       "      <td>-86.99988</td>\n",
       "      <td>-6.12034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200004</th>\n",
       "      <td>40.92442</td>\n",
       "      <td>-43.26026</td>\n",
       "      <td>-18.72100</td>\n",
       "      <td>-11.72495</td>\n",
       "      <td>-19.69395</td>\n",
       "      <td>-10.54229</td>\n",
       "      <td>-9.91945</td>\n",
       "      <td>-14.85633</td>\n",
       "      <td>9.37409</td>\n",
       "      <td>-0.93093</td>\n",
       "      <td>...</td>\n",
       "      <td>17.63167</td>\n",
       "      <td>-203.56276</td>\n",
       "      <td>27.10714</td>\n",
       "      <td>36.90795</td>\n",
       "      <td>0.62431</td>\n",
       "      <td>-40.23377</td>\n",
       "      <td>-83.22141</td>\n",
       "      <td>4.44391</td>\n",
       "      <td>73.15568</td>\n",
       "      <td>3.25023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251625</th>\n",
       "      <td>51.51566</td>\n",
       "      <td>57.56765</td>\n",
       "      <td>-2.64857</td>\n",
       "      <td>-4.91725</td>\n",
       "      <td>-23.56405</td>\n",
       "      <td>0.85009</td>\n",
       "      <td>-17.36973</td>\n",
       "      <td>11.53281</td>\n",
       "      <td>-0.94416</td>\n",
       "      <td>-0.44701</td>\n",
       "      <td>...</td>\n",
       "      <td>19.47616</td>\n",
       "      <td>-55.85795</td>\n",
       "      <td>-73.33446</td>\n",
       "      <td>44.67472</td>\n",
       "      <td>-4.15276</td>\n",
       "      <td>149.79434</td>\n",
       "      <td>-113.40535</td>\n",
       "      <td>7.92503</td>\n",
       "      <td>141.56348</td>\n",
       "      <td>8.79724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251626</th>\n",
       "      <td>49.94868</td>\n",
       "      <td>48.06760</td>\n",
       "      <td>-3.65467</td>\n",
       "      <td>-8.93936</td>\n",
       "      <td>-29.64670</td>\n",
       "      <td>-2.42913</td>\n",
       "      <td>-11.37464</td>\n",
       "      <td>7.05295</td>\n",
       "      <td>15.04007</td>\n",
       "      <td>13.68497</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04067</td>\n",
       "      <td>-261.29108</td>\n",
       "      <td>-90.93597</td>\n",
       "      <td>58.34540</td>\n",
       "      <td>-6.57932</td>\n",
       "      <td>36.79059</td>\n",
       "      <td>32.19586</td>\n",
       "      <td>1.45334</td>\n",
       "      <td>140.34302</td>\n",
       "      <td>-1.44199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251627</th>\n",
       "      <td>45.40128</td>\n",
       "      <td>38.26969</td>\n",
       "      <td>-15.07650</td>\n",
       "      <td>-3.31269</td>\n",
       "      <td>0.87066</td>\n",
       "      <td>-8.09099</td>\n",
       "      <td>-14.67702</td>\n",
       "      <td>3.66075</td>\n",
       "      <td>5.14198</td>\n",
       "      <td>0.65322</td>\n",
       "      <td>...</td>\n",
       "      <td>20.65412</td>\n",
       "      <td>-143.53649</td>\n",
       "      <td>-33.92068</td>\n",
       "      <td>196.54495</td>\n",
       "      <td>26.27162</td>\n",
       "      <td>115.49923</td>\n",
       "      <td>-130.81155</td>\n",
       "      <td>4.71753</td>\n",
       "      <td>285.25134</td>\n",
       "      <td>3.44482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251628</th>\n",
       "      <td>44.06831</td>\n",
       "      <td>10.85663</td>\n",
       "      <td>-28.45948</td>\n",
       "      <td>31.90792</td>\n",
       "      <td>5.14640</td>\n",
       "      <td>-23.67390</td>\n",
       "      <td>7.89138</td>\n",
       "      <td>2.79403</td>\n",
       "      <td>1.70776</td>\n",
       "      <td>12.41229</td>\n",
       "      <td>...</td>\n",
       "      <td>9.08009</td>\n",
       "      <td>-143.41301</td>\n",
       "      <td>-188.23546</td>\n",
       "      <td>-87.95495</td>\n",
       "      <td>-7.37069</td>\n",
       "      <td>50.86357</td>\n",
       "      <td>197.18905</td>\n",
       "      <td>-0.10796</td>\n",
       "      <td>40.65367</td>\n",
       "      <td>-5.44536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251629</th>\n",
       "      <td>42.06088</td>\n",
       "      <td>16.22934</td>\n",
       "      <td>13.77411</td>\n",
       "      <td>6.98701</td>\n",
       "      <td>-3.96009</td>\n",
       "      <td>-15.51985</td>\n",
       "      <td>4.28617</td>\n",
       "      <td>-7.19229</td>\n",
       "      <td>8.47825</td>\n",
       "      <td>-2.02779</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.48349</td>\n",
       "      <td>15.78404</td>\n",
       "      <td>-45.86196</td>\n",
       "      <td>-32.17637</td>\n",
       "      <td>2.72679</td>\n",
       "      <td>32.71618</td>\n",
       "      <td>-10.87536</td>\n",
       "      <td>1.27817</td>\n",
       "      <td>12.98601</td>\n",
       "      <td>14.77818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51630 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7   \\\n",
       "200000  45.09540 -57.29138  20.05392   0.10414  12.00346 -14.31259   2.54547   \n",
       "200001  45.11673 -18.39958  -1.61552  -3.67929 -13.24027  -6.84375 -10.33838   \n",
       "200002  46.85191   9.44824   0.31518 -16.85413  15.42389 -15.82587 -21.21385   \n",
       "200003  45.79644 -36.86230  21.99320 -10.42360  -2.89410  -8.84010 -23.73864   \n",
       "200004  40.92442 -43.26026 -18.72100 -11.72495 -19.69395 -10.54229  -9.91945   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "251625  51.51566  57.56765  -2.64857  -4.91725 -23.56405   0.85009 -17.36973   \n",
       "251626  49.94868  48.06760  -3.65467  -8.93936 -29.64670  -2.42913 -11.37464   \n",
       "251627  45.40128  38.26969 -15.07650  -3.31269   0.87066  -8.09099 -14.67702   \n",
       "251628  44.06831  10.85663 -28.45948  31.90792   5.14640 -23.67390   7.89138   \n",
       "251629  42.06088  16.22934  13.77411   6.98701  -3.96009 -15.51985   4.28617   \n",
       "\n",
       "              8         9         10  ...        81         82         83  \\\n",
       "200000  -3.33986  -3.60175  -8.99414  ...   7.15503  -81.48297   34.91722   \n",
       "200001 -11.12891  16.56924   6.70243  ...   8.26246 -138.26547   23.59451   \n",
       "200002 -10.16067  14.45113   2.22865  ...  13.24783  -91.25475   41.12300   \n",
       "200003  -9.82956  13.08399   0.57577  ...   8.13403 -194.21155   55.55883   \n",
       "200004 -14.85633   9.37409  -0.93093  ...  17.63167 -203.56276   27.10714   \n",
       "...          ...       ...       ...  ...       ...        ...        ...   \n",
       "251625  11.53281  -0.94416  -0.44701  ...  19.47616  -55.85795  -73.33446   \n",
       "251626   7.05295  15.04007  13.68497  ...   6.04067 -261.29108  -90.93597   \n",
       "251627   3.66075   5.14198   0.65322  ...  20.65412 -143.53649  -33.92068   \n",
       "251628   2.79403   1.70776  12.41229  ...   9.08009 -143.41301 -188.23546   \n",
       "251629  -7.19229   8.47825  -2.02779  ...  -2.48349   15.78404  -45.86196   \n",
       "\n",
       "               84        85         86         87       88         89  \\\n",
       "200000   15.11917  -6.09056  -78.52893  -46.87559  2.89571   64.25949   \n",
       "200001   60.99156   4.18891  105.75496 -126.39851 -3.80727   55.00532   \n",
       "200002   55.22389   8.33048    7.57355   17.34516  0.21543  -58.34520   \n",
       "200003   21.65387   6.41164  -47.18867 -212.14270 -4.67550  -86.99988   \n",
       "200004   36.90795   0.62431  -40.23377  -83.22141  4.44391   73.15568   \n",
       "...           ...       ...        ...        ...      ...        ...   \n",
       "251625   44.67472  -4.15276  149.79434 -113.40535  7.92503  141.56348   \n",
       "251626   58.34540  -6.57932   36.79059   32.19586  1.45334  140.34302   \n",
       "251627  196.54495  26.27162  115.49923 -130.81155  4.71753  285.25134   \n",
       "251628  -87.95495  -7.37069   50.86357  197.18905 -0.10796   40.65367   \n",
       "251629  -32.17637   2.72679   32.71618  -10.87536  1.27817   12.98601   \n",
       "\n",
       "              90  \n",
       "200000   0.78578  \n",
       "200001  -3.42354  \n",
       "200002   3.92760  \n",
       "200003  -6.12034  \n",
       "200004   3.25023  \n",
       "...          ...  \n",
       "251625   8.79724  \n",
       "251626  -1.44199  \n",
       "251627   3.44482  \n",
       "251628  -5.44536  \n",
       "251629  14.77818  \n",
       "\n",
       "[51630 rows x 90 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peak at the data if desired\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model  (Note, this may take a bit of time for larger values of _num_est_. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=8, n_estimators=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=8, n_estimators=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=8, n_estimators=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "num_est=2\n",
    "\n",
    "skl_model = RandomForestRegressor(n_estimators=num_est, max_depth=8)\n",
    "skl_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn (CPU only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5 ms ± 375 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "skl_time = %timeit -o skl_model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert scikit-learn model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convert(skl_model, 'torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time PyTorch - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.6 ms ± 635 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "pred_cpu_hb = %timeit -o model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch PyTorch from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time PyTorch - GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.1 ms ± 767 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pred_gpu_hb = %timeit -o model.predict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
